一、核心原则（Underlying Principles）
在任何具体框架与方法之前，以下几条原则是所有有效提示词写作的基础，必须贯穿始终：

清晰性与具体性（Clarity & Specificity）

要点：避免模糊、宽泛的指令；对输出内容进行精确描述。

原因：LLM 本质上是概率模型，它会基于提示中出现的关键词与结构进行生成；如果提示过于笼统，模型容易生成偏离预期的结果。

示例：

不佳示例：“写一个故事。”

优良示例：“写一个关于机器人在反乌托邦未来中学会同情心的短篇故事，整体基调偏向忧郁。”

上下文至上（Context is King）

要点：在提示中预先提供足够的背景信息，明确所指术语与场景，让模型“了解来龙去脉”。

原因：模型并不具备真正的常识理解或场景记忆，提示中要主动填补这些信息缺口，减少错误理解的可能性。

包含内容：定义专业术语、阐明所处场景与角色、说明预期输出的用途与格式。

角色设定（Role Prompting）

要点：为模型分配一个“身份”或“角色”，例如“你是一位资深营销文案策划师”或“你是一位简明扼要的助教”。

原因：通过赋予特定角色，能够引导模型在知识面、风格、措辞等方面作出对应调整，从而更贴合目标需求。

效果：有助于统一输出口吻，提高专业度和针对性。

示例驱动（Few-Shot Learning）

要点：在提示中提供若干（通常 1～3 个左右）示例，展示“理想输出”格式与风格。

原因：比起仅陈述需求，示例更能直观告诉模型如何“去做”，尤其对复杂任务或多步骤任务帮助明显。

示例格式：若想要生成问答对、摘要或代码片段，都可以在提示里先示范一两个，模型再以此为参照生成新的内容。

输出格式控制（Output Format Control）

要点：清楚指明结果应以何种形式呈现，例如“请以要点形式列出”、“请返回 JSON 结构”、“请给出一首押韵的诗歌”等。

原因：减少后续手动整理、提取等工作量，提升提示的“可用性”。

注意：若要生成多类型内容（如同时有文字与表格），要在提示里明确区分。

参数调节理解（Temperature & Top_P）

Temperature：控制生成内容的随机性，值越高（接近 1），输出越发散；值越低（接近 0），输出越集中于高概率词。

Top_P（核采样）：控制输出多样性，从概率分布中先筛选出累积概率达到 Top_P 的词汇，再从中随机采样。

实践：在需要“创造力”或“灵感”类场景时可适当提高 Temperature；在追求“准确、稳定”的场景（如数学推导）时设置较低 Temperature，并可配合 Top_P 低值使用。

迭代优化（Iterative Refinement）

要点：绝大多数时候，一次提示难以一次性达到最优效果；要迭代地测试、观察模型输出，并根据输出进行提示微调。

步骤：

初步设计提示（基础版）。

运行模型，评估输出质量与偏差。

针对性地改进提示（增加上下文、修改措辞、添加示例或格式要求）。

重复以上步骤，直到满足预期为止。

二、主要框架与方法（Frameworks & Methodologies）
以下梳理了当前最常见且已被实践验证的几种提示词写作框架，它们可以单独使用，也可以根据实际需求进行组合或变形。

1. CREATES 框架
来源：OpenAI 官方提出
定位：一个系统化、结构化的提示设计思路，适用于复杂任务
由来：CREATES 是首字母缩写，对应 6 个关键要素。

C – Context（上下文）
在提示开头说明所处场景、给出必要背景信息。

示例：介绍任务应用领域、受众群体、已有数据或前置条件。

R – Role（角色）
明确分配模型“扮演”的角色或身份。

示例：“你是一名经验丰富的中英翻译专家”或“你是一位财经领域的分析师”。

E – Examples（示例）
提供 1～3 组与任务相似、且符合预期格式的示例。

示例：给出一段示范问答、摘要或代码，让模型“模仿”。

A – Task（任务）
清晰地陈述核心任务，即“需要模型做什么”。

示例：“请将以下英文新闻摘要翻译成中文，并保留原文的关键信息”。

T – Tone（语气）
说明希望输出时所采用的“表达风格”“口吻”或“写作语调”。

常见选项：正式（formal）、非正式（informal）、幽默（humorous）、客观（objective）等。

S – Structure（结构）
指定输出的“呈现形式”“排版格式”“数据结构”。

示例：“请以编号要点方式列出，或请以 JSON 格式返回，键名为 ‘title’、‘body’ 等”。

优势与不足
优势

完整、系统，能够照顾任务的各个环节，从准备到输出都非常细化；

对于流程复杂、需要多项要素协同的任务效果显著。

不足

引入过多要素，提示文字较长，对新手或简单任务可能显得“繁琐”；

某些要素（例如示例）不易一次性准备，需要额外时间。

2. Chain-of-Thought（CoT）思维链提示
核心思想：引导模型在给出最终答案之前“写出推理过程”，以提高复杂推理任务的准确率。

原理
模型在训练过程中学到了一定程度的“隐式推理能力”，通过在提示中加入诸如“让我们一步步分析”或“请解释你的推理过程”，可以激发模型将其内部的推理链“显性化”，从而在做数学运算、逻辑推理、复杂判断时减少遗漏或错误。

典型写法

“问题：23 × 47 等于多少？让我们一步步推理。首先 23×7=161，然后 23×40=920，将二者相加得……最终答案是……”

在需要回答推理题时，在提示末尾加上“请详细说明你的思考过程”或“请写出推理步骤，再给出答案”。

优劣对比

优势：对解决多步运算题、逻辑题、常识推断题等效果显著；能够生成“可检查的思路”，便于人工核验；

不足：会显著增加回答长度，不适用于仅需简明答案的场景；在某些任务中可能冗余。

2.1 零示例思维链（Zero-Shot CoT）
概念：与 CoT 类似，但不提供示例，仅在提示中加一句“让我们一步步思考”，即可激发模型输出推理过程。

优点：实施门槛低，无需准备“示例”；

缺点：对于特别复杂或高度专业领域的推理任务，零示例版本的效果可能不如完整 CoT。

3. ReAct（Reason + Act）框架
核心思想：在“思考（Reason）”与“行动（Act）”之间形成闭环，让模型在相对有限的会话中既能够自我推理，也能主动调用外部工具（如搜索引擎、计算器、API 等），然后再基于获取的信息继续推理与行动。

具体做法

思考（Reason）：首先让模型生成“我需要什么信息”“应该使用何种工具”等内部思考。

行动（Act）：模型将思考结果转化为具体的“工具调用”步骤，例如“搜索：东京最新人口统计数据”，“调用计算器完成 23×47 运算” 等。

迭代：根据工具返回的结果，模型再进行进一步的推理与行动，直到生成最终答案。

典型示例

markdown
复制
编辑
你是一名研究助理，需要获取东京当前的人口数据。  
1. 思考：我需要使用网络搜索工具来查找最新人口。  
2. 行动：使用搜索引擎查询“2025 年东京人口统计”。  
3. 思考：从返回结果中提取有效数字，并进行验证。  
4. 行动：输出“截至 2025 年，东京人口约为 XXXX 万”。
优势

适用于需要结合外部信息或多步骤交互的任务；

能让 LLM 与现实世界“实时”连接，更加灵活。

不足

实现复杂，需要先给模型连接到外部工具的能力；

对于只需纯文本生成的任务，ReAct 可能显得“多此一举”。

4. 知识生成（Knowledge Generation, KG）
核心思想：在正式执行任务之前，先让模型“生成与主题相关的知识点”——相当于给模型做一次快速的“预热”，然后再让它基于这些知识展开后续任务。

操作步骤

知识提取：提示模型 “请生成关于 [主题] 的一系列要点或事实”。

任务执行：将上述生成的要点作为附加上下文，嵌入到后续的主任务提示中。

输出：基于“先生成的知识 + 主任务指令”，生成更具专业性、准确性的回答。

示例

复制
编辑
第一步提示：请生成一个包含 5 条关于“人工智能在医疗诊断中应用”的事实清单。  
（模型生成：1. … 2. … 3. …）  
第二步提示：基于上述 5 条事实，撰写一篇 500 字的分析报告，讨论 AI 技术在医疗诊断领域的机遇与挑战。
优势

特别适合高度专业或数据密集型场景，让模型提前“进入角色”；

提升输出的可靠性与完整性。

不足

增加了额外一步骤，提示链条更长；

若生成的知识要点本身有偏差，则后续任务也会受到影响。

三、高级技术（Advanced Techniques）
当对以下基础方法熟练掌握之后，可以考虑将它们与更高级的提示技术结合，以进一步提升质量或扩展应用场景。

提示链（Prompt Chaining）

定义：将一个复杂任务拆分为若干子任务（也可能对应若干子提示），按顺序依次执行，并将每个子任务的输出作为下一个子任务的输入。

示例：

子提示 1：从长篇文章中提取所有关键人物与时间节点。

子提示 2：根据提取结果，自动生成事件时间线。

子提示 3：基于事件时间线，撰写一篇结构化的历史分析。

优点：分而治之，能有效解决单次提示难以覆盖的复杂问题；

缺点：流程较长，需要对每步输出结果进行严格校验，否则后续错误会级联。

自洽性（Self-Consistency）

定义：对同一个提示多次采样生成多个候选答案，然后通过某种方式（例如多数投票或相似度打分）选出“最具一致性”或“最可能正确”的结果。

意义：对复杂推理任务，单次生成结果可能存在“走偏”或“遗漏”；通过多次采样，提取具有共性的高置信内容，提高整体准确率。

实施要点：

需要设置合适的采样参数（如设置较高 Temperature）；

考虑后续“筛选”策略，如“关键词匹配度”或“逻辑连贯性”评价。

主动提示（Active Prompting）

定义：允许模型在正式给出最终答案之前，先对用户的需求进行“澄清性提问”，确保理解无歧义后再执行任务。

示例：

复制
编辑
用户提示：帮我写一份市场分析报告。  
模型思考（主动提问）：您需要分析的市场是哪个行业？覆盖哪个地区？报告目标受众是谁？  
用户回答后：生成最终报告。
优点：减少因提示不明确而产生的误差，提高对话效率；

缺点：对话回合数增多，用户可能认为过程较“啰嗦”。

检索增强生成（Retrieval-Augmented Generation, RAG）

定义：将 LLM 与专门的外部知识库（如向量数据库、文档检索系统等）结合，先检索相关内容，再将检索结果与核心提示一起输入模型进行生成。

流程：

以用户提示为检索查询，找到若干相关文档段落。

将这些文档段落与用户原始提示合并，形成“检索上下文 + 提示”。

LLM 基于上述扩充上下文生成更精确、带有引用或证据依据的回答。

优势：解决 LLM 长尾知识缺失问题，尤其适合需要引用最新数据或特定领域知识的场景；

挑战：需要搭建检索系统、维护索引，并设计好检索与生成之间的衔接策略。

四、进一步学习与资源推荐
Learn Prompting（英文）
网址：https://learnprompting.org/
内容：从基础到进阶的提示教程，并配有大量示例与实践练习。

OpenAI 文档——提示工程指南（英文）
网址：https://platform.openai.com/docs/guides/prompt-engineering
内容：官方示例、多种 API 参数解析，以及如何将提示与模型配置结合优化生成质量。

Prompt Engineering Guide（英文）
网址：https://www.promptingguide.ai/
内容：系统梳理当前主流提示模式与最佳实践；涵盖基础概念、各类框架与高级技术，有社区贡献的示例库。

开源项目与示例

LangChain（Python 库）：集成了多种提示模板、提示链与 RAG 示例，适合动手实践。

PromptLibrary：GitHub 上许多社区维护的 prompt 收藏仓库，可直接借鉴真实案例。

结论与建议
结合需求选择框架

简单任务：可仅依托“清晰与具体”“输出格式控制”原则，配合少量示例，即可获得较好效果；

复杂任务：优先考虑 CREATES 全流程或将 CoT/Zero-Shot CoT 与知识生成结合，必要时引入 Prompt Chaining 与 RAG。

反复实验与迭代

在正式使用前，先搭建小规模测试，快速评估不同提示组合的效果；

可将多个提示思路混合：先通过 KG 生成知识，再用 CoT 做过程推理，最后输出。

注意成本与效益

每次模型调用均有延迟与费用，需要在准确性与资源消耗之间平衡；

若模型已在特定领域“表现尚可”，可减少示例或上下文长度，以节约额度。

跟踪前沿动态

Prompt 工程是一个快速迭代的领域，新方法层出不穷；定期关注社区、学习官方文档与实战范例，有助于发现更高效的策略。

通过对上述核心原则、常见框架与高级技术的系统梳理，您可以在提示设计之初就建立“全局思路”，进而根据实际场景灵活运用、组合相应方法，不断迭代优化，从而让大语言模型在各类任务中更好地“发挥所长”。








